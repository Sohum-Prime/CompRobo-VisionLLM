{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089221a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in /Users/zaynpatel/.local/lib/python3.9/site-packages (from torch) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: amazon-textract-overlayer 0.0.11 has a non-standard dependency specifier Pillow>=9.2.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of amazon-textract-overlayer or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: amazon-textract-overlayer 0.0.11 has a non-standard dependency specifier pypdf>=2.5.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of amazon-textract-overlayer or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ae844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcdca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/zaynpatel/opt/miniconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229ad3f",
   "metadata": {},
   "source": [
    "### Prepare images and \"Train\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9c04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom class to add image identifiers to vector representations for better analysis\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class UnderstandImages(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir # this will be the dictionary passed in the custom class UnderstandImages {'className' : 'file/directory/for/class'}\n",
    "        self.transform = transform # transform is the same as the block below - we want to begin converting it into tensor-like format\n",
    "        self.img_names = [] # initializing this as an empty list because I want to iterate over each class directory and list their files\n",
    "\n",
    "        for classname, directoryname in self.img_dir.items():\n",
    "            image_names = os.listdir(directoryname) # list the items in the directory - does this list the items on every loop?\n",
    "            for img_name in image_names:\n",
    "                img_path = os.path.join(directoryname, img_name) # join the directory with the image names\n",
    "                self.img_names.append((img_path, classname))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names) \n",
    "\n",
    "    # override this class so I can get image and filename\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, classname = self.img_names[idx] # we need to tuple unpack because we get two items in self.img_names based on our append\n",
    "        image = Image.open(img_path) # convert raw images into tensors\n",
    "        if self.transform: # apply the transform to each image \n",
    "            image = self.transform(image)\n",
    "\n",
    "        filename = os.path.basename(img_path) # want to see the images in the output filenames.txt as well\n",
    "    \n",
    "        return image, classname, filename # return the image and classname because we want to use these for the labeling later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46f2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224), # crop to the center since we assume most of the important features are in the center\n",
    "    transforms.ToTensor(), # converts a PIL image, like the one defined in the above code block to a PyTorch tensor or np.ndarray\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # normalize based on the values of the resnet when it was originally trained\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbd688f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "resnet18.fc = torch.nn.Identity() # remove the final classification layer of the NN so I can just get the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "165d541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np # need a way to persist data so use np array to save items to .npy files too\n",
    "\n",
    "img_dirs = {\n",
    "    'After Room 126' : '/Users/zaynpatel/vision/visionLLM/CompRobo-VisionLLM/featureExtraction/train/AFTER_126',\n",
    "    'MAC Entrance' : '/Users/zaynpatel/vision/visionLLM/CompRobo-VisionLLM/featureExtraction/train/MAC_Entrance',\n",
    "    'Near Elevator' : '/Users/zaynpatel/vision/visionLLM/CompRobo-VisionLLM/featureExtraction/train/QEA_TO_ELEVATOR'\n",
    "}\n",
    "\n",
    "dataset = UnderstandImages(img_dir = img_dirs, transform=transform) # use the custom defined class to get filename in the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=9, shuffle=False, num_workers=0) # pass in dataset of images, batch_size which is the number of images getting passed to the model, num_workers is number working in parallel on machine\n",
    "\n",
    "resnet18.eval()\n",
    "\n",
    "featuresList = []\n",
    "filenamesList = []\n",
    "classnameList = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, classnames, filenames in dataloader: # based on the class we defined, we know there are two inputs to dataloader so we unpack those here for use\n",
    "        features = resnet18(inputs) # apply the resnet on the images\n",
    "        # always confirm that we're unpacking the same number of values as we are the \n",
    "        for feature, filename, classname in zip(features, filenames, classnames): # zip all output feature vectors and filenames together so we can visualize and compare after\n",
    "            features_np = feature.detach().cpu().numpy().flatten() # error: did features.detch() instead of feature.detach() which meant ...\n",
    "            featuresList.append(features_np)\n",
    "            filenamesList.append(filename)\n",
    "            classnameList.append(classname) \n",
    "\n",
    "featuresArray = np.array(featuresList)\n",
    "np.save('data.npy', featuresArray)\n",
    "\n",
    "with open('filenames.txt', 'w') as f:\n",
    "    for filename, classname in zip(filenamesList, classnameList):\n",
    "        f.write(f\"{filename}, {classname}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d78102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30  1]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_4.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3773.JPG', 'after126_5.JPG']\n",
      "[1 0]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_5.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_5.JPG', 'after126_4.JPG']\n",
      "[28  3]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_7.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3774.JPG', 'after126_6.JPG']\n",
      "[3 2]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_6.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_6.JPG', 'after126_7.JPG']\n",
      "[31  5]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_2.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3770.JPG', 'after126_3.JPG']\n",
      "[5 4]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_3.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_3.JPG', 'after126_2.JPG']\n",
      "[23 26]\n",
      "[' Near Elevator\\n', ' Near Elevator\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_1.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' Near Elevator\\n'], Images: ['IMG_3769.JPG', 'IMG_3781.JPG']\n",
      "[29 10]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_10.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3777.JPG', 'after126_9.JPG']\n",
      "[ 8 26]\n",
      "[' After Room 126\\n', ' Near Elevator\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_11.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' Near Elevator\\n'], Images: ['after126_11.JPG', 'IMG_3781.JPG']\n",
      "[31  4]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_8.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3770.JPG', 'after126_2.JPG']\n",
      "[10  7]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  After Room 126\n",
      ", Actual image: after126_9.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_9.JPG', 'after126_10.JPG']\n",
      "[18 12]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3723.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3724.JPG', 'IMG_3722.JPG']\n",
      "[14 15]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3722.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3721.JPG', 'IMG_3725.JPG']\n",
      "[21 14]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3720.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3716.JPG', 'IMG_3721.JPG']\n",
      "[15 12]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3721.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3725.JPG', 'IMG_3722.JPG']\n",
      "[14 12]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3725.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3721.JPG', 'IMG_3722.JPG']\n",
      "[17 20]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3719.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3718.JPG', 'IMG_3717 2.JPG']\n",
      "[20 16]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3718.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3717 2.JPG', 'IMG_3719.JPG']\n",
      "[11 14]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3724.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3723.JPG', 'IMG_3721.JPG']\n",
      "[20 17]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3726.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3717 2.JPG', 'IMG_3718.JPG']\n",
      "[17 21]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3717 2.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3718.JPG', 'IMG_3716.JPG']\n",
      "[20 13]\n",
      "[' MAC Entrance\\n', ' MAC Entrance\\n']\n",
      "Actual class:  MAC Entrance\n",
      ", Actual image: IMG_3716.JPG\n",
      "Nearest neighbors' classes: [' MAC Entrance\\n', ' MAC Entrance\\n'], Images: ['IMG_3717 2.JPG', 'IMG_3720.JPG']\n",
      "[24  3]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3783.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3782.JPG', 'after126_6.JPG']\n",
      "[23 26]\n",
      "[' Near Elevator\\n', ' Near Elevator\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3769.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' Near Elevator\\n'], Images: ['IMG_3769.JPG', 'IMG_3781.JPG']\n",
      "[32  5]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3782.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3771.JPG', 'after126_3.JPG']\n",
      "[26 23]\n",
      "[' Near Elevator\\n', ' Near Elevator\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3780.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' Near Elevator\\n'], Images: ['IMG_3781.JPG', 'IMG_3769.JPG']\n",
      "[27  8]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3781.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3779.JPG', 'after126_11.JPG']\n",
      "[ 8 26]\n",
      "[' After Room 126\\n', ' Near Elevator\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3779.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' Near Elevator\\n'], Images: ['after126_11.JPG', 'IMG_3781.JPG']\n",
      "[3 2]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3774.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_6.JPG', 'after126_7.JPG']\n",
      "[10  7]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3777.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_9.JPG', 'after126_10.JPG']\n",
      "[1 0]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3773.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_5.JPG', 'after126_4.JPG']\n",
      "[31  5]\n",
      "[' Near Elevator\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3770.JPG\n",
      "Nearest neighbors' classes: [' Near Elevator\\n', ' After Room 126\\n'], Images: ['IMG_3770.JPG', 'after126_3.JPG']\n",
      "[5 4]\n",
      "[' After Room 126\\n', ' After Room 126\\n']\n",
      "Actual class:  Near Elevator\n",
      ", Actual image: IMG_3771.JPG\n",
      "Nearest neighbors' classes: [' After Room 126\\n', ' After Room 126\\n'], Images: ['after126_3.JPG', 'after126_2.JPG']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data = np.load('data.npy', allow_pickle=True) # we said pickle is used because ...\n",
    "with open('filenames.txt', 'r') as f:\n",
    "    filename = f.readlines()\n",
    "    classnames_list = []\n",
    "    img_file_list = []\n",
    "    for files in filename:\n",
    "        # definitely could do this in a list comprehension\n",
    "        split_files = files.split(',')\n",
    "        img_files = split_files[0]\n",
    "        classname_split = split_files[1]\n",
    "        img_file_list.append(img_files)\n",
    "        classnames_list.append(classname_split)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(data) # ball_tree eliminates datapoints that are too far from the query point, making search faster\n",
    "distances, indices = nbrs.kneighbors(data)\n",
    "\n",
    "for i, neighbor_indices in enumerate(indices):\n",
    "    # Skip the first neighbor if it's the feature itself - it is in this case   \n",
    "    neighbor_indices = neighbor_indices[1:] if len(neighbor_indices) > 1 else neighbor_indices\n",
    "    # Get the class names of the neighbors\n",
    "    neighbor_classnames = [classnames_list[idx] for idx in neighbor_indices] # iterate through the indices which are pairs like [28, 3] and retrieve this corresponding index from the lists where these came from.\n",
    "    neighbor_filenames = [img_file_list[idx] for idx in neighbor_indices]\n",
    "    # Get the actual class name for the test feature\n",
    "    actual_classname = classnames_list[i]\n",
    "    actual_image = img_file_list[i]\n",
    "\n",
    "    print(f\"Actual class: {actual_classname}, Actual image: {actual_image}\")\n",
    "    print(f\"Nearest neighbors' classes: {neighbor_classnames}, Images: {neighbor_filenames}\")\n",
    "\n",
    "#print(f'these are distances {distances}, and indices {indices}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "66c511c1ad3b987e9adeb56a6d9aa6aa351c712ec4b3431ede2074b94c691dfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
